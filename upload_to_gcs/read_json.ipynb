{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lõi CPU: 10\n"
     ]
    }
   ],
   "source": [
    "# Check CPU information to decide the thread and chunk\n",
    "# Số lõi CPU\n",
    "cpu_count = os.cpu_count()\n",
    "print(f\"Số lõi CPU: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước trung bình mỗi dòng: 798.08 bytes\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra kích thước trung bình của một dòng dữ liệu:\n",
    "input_file = '/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/glamira.json'\n",
    "\n",
    "# Đọc một số dòng đầu tiên và tính kích thước trung bình\n",
    "def estimate_line_size(file_path, num_lines=1000):\n",
    "    total_size = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            total_size += len(line.encode('utf-8'))\n",
    "            if i + 1 >= num_lines:\n",
    "                break\n",
    "    return total_size / num_lines\n",
    "\n",
    "avg_line_size = estimate_line_size(input_file)\n",
    "print(f\"Kích thước trung bình mỗi dòng: {avg_line_size:.2f} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước mỗi chunk (dòng): 21526473\n"
     ]
    }
   ],
   "source": [
    "# Ước lượng chunk\n",
    "available_ram = 32 * 1024**3  # Ví dụ: 2GB RAM khả dụng (thay số này theo máy bạn)\n",
    "chunk_size = int(available_ram / avg_line_size / 2)  # Sử dụng nửa RAM khả dụng\n",
    "print(f\"Kích thước mỗi chunk (dòng): {chunk_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output đã được lưu vào /Users/giakhanh/Desktop/Data Engineer/glamira_project/project/upload_to_gcs/output.txt\n"
     ]
    }
   ],
   "source": [
    "# Stream JSON file to avoid loading the entire file into memory\n",
    "input_file = '/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/glamira.json'\n",
    "output_file = '/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/upload_to_gcs/output.txt'\n",
    "\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for i, line in enumerate(infile):\n",
    "        try:\n",
    "            obj = json.loads(line)  # Parse từng dòng JSON\n",
    "            outfile.write(json.dumps(obj, indent=4))  # Ghi object JSON dưới dạng string\n",
    "            outfile.write('\\n')  # Thêm dòng mới\n",
    "            if i >= 10:  # Giới hạn ghi 10 dòng đầu tiên (nếu cần)\n",
    "                break\n",
    "        except json.JSONDecodeError as e:\n",
    "            outfile.write(f\"Lỗi ở dòng {i + 1}: {e}\\n\")\n",
    "            break\n",
    "\n",
    "print(f\"Output đã được lưu vào {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found JSON file: /Users/giakhanh/Desktop/Data Engineer/glamira_project/project/IP_Glamira_data/79_50_119_237.json\n"
     ]
    }
   ],
   "source": [
    "def find_and_print_first_json_recursive(folder_path):\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".json\"):\n",
    "                    print(f\"Found JSON file: {os.path.join(root, file)}\")\n",
    "                    return  # Dừng sau khi tìm thấy file JSON đầu tiên\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Đường dẫn tới folder cần kiểm tra\n",
    "folder_path = \"/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/IP_Glamira_data\"\n",
    "find_and_print_first_json_recursive(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of the JSON file:\n"
     ]
    }
   ],
   "source": [
    "def print_json_file(file_path):\n",
    "    try:\n",
    "        # Mở file JSON\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            try:\n",
    "                data = json.load(json_file)  # Parse nội dung JSON\n",
    "                print(\"Content of the JSON file:\")\n",
    "                print(json.dumps(data, indent=4))  # In nội dung JSON (đẹp mắt)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Đường dẫn tới file JSON cần in\n",
    "file_path = \"/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/mappingmapping_glamira_IP.json\"\n",
    "print_json_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n"
     ]
    }
   ],
   "source": [
    "def print_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            content = json_file.read()\n",
    "            try:\n",
    "                # Tách từng JSON object và parse từng cái\n",
    "                objects = content.split(\"\\n\")  # Giả sử mỗi JSON object nằm trên một dòng\n",
    "                for idx, obj in enumerate(objects):\n",
    "                    if obj.strip():  # Loại bỏ dòng trống\n",
    "                        data = json.loads(obj.strip())  # Parse từng JSON object\n",
    "                        print(f\"Content of JSON object {idx + 1}:\")\n",
    "                        print(json.dumps(data, indent=4))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Đường dẫn tới file JSON cần in\n",
    "file_path = \"/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/mappingmapping_glamira_IP.json\"\n",
    "print_json_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu danh sách unique IPs (với dấu .) vào: /Users/giakhanh/Desktop/Data Engineer/glamira_project/project/mapping/unique_ips.json\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn thư mục chứa file JSON và file đầu ra\n",
    "input_directory = '/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/IP_Glamira_data'\n",
    "output_file = '/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/mapping/unique_ips.json'\n",
    "\n",
    "# Hàm xử lý một nhóm file\n",
    "def process_files(files):\n",
    "    ips = []\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):  # Chỉ lấy file JSON\n",
    "            ip_name = os.path.splitext(file)[0]  # Bỏ phần mở rộng\n",
    "            ip_name_with_dots = ip_name.replace('_', '.')  # Thay _ thành .\n",
    "            ips.append(ip_name_with_dots)\n",
    "    return ips\n",
    "\n",
    "# Lấy danh sách file JSON từ thư mục\n",
    "all_files = os.listdir(input_directory)\n",
    "\n",
    "# Chia file thành nhiều nhóm để xử lý song song\n",
    "chunk_size = len(all_files) // os.cpu_count()  # Tùy thuộc vào số CPU\n",
    "chunks = [all_files[i:i + chunk_size] for i in range(0, len(all_files), chunk_size)]\n",
    "\n",
    "# Dùng ThreadPoolExecutor để xử lý song song\n",
    "unique_ips = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(process_files, chunks)\n",
    "    for ips in results:\n",
    "        unique_ips.extend(ips)\n",
    "\n",
    "# Lưu unique IPs vào file JSON\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(unique_ips, outfile, indent=4)\n",
    "\n",
    "print(f\"Đã lưu danh sách unique IPs (với dấu .) vào: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/crawl_data/product_name.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/giakhanh/Desktop/Data Engineer/glamira_project/project/crawl_data/product_name.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                         _id  time_stamp               ip  \\\n",
      "0  5ed8cb2bc671fc36b74653ad  1591266092    37.170.17.183   \n",
      "1  5ed8cb2b4c9ffc36e828fabe  1591266092   194.193.38.240   \n",
      "2  5ed8cb2cfeae1f377811165c  1591266092  212.237.237.184   \n",
      "3  5ed8cb2a56b3dd3742261b8c  1591266091     121.200.6.91   \n",
      "4  5ed8cb2a796d133700cefa27  1591266091    24.133.169.84   \n",
      "\n",
      "                                          user_agent resolution  user_id_db  \\\n",
      "0  Mozilla/5.0 (iPhone; CPU iPhone OS 13_4_1 like...    375x667    502567.0   \n",
      "1  Mozilla/5.0 (Linux; Android 10; SM-N960F) Appl...    412x846    503390.0   \n",
      "2  Mozilla/5.0 (Linux; Android 9; SM-A202F) Apple...    360x780         NaN   \n",
      "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4...   834x1112         NaN   \n",
      "4  Mozilla/5.0 (Windows NT 6.1; Win64; x64) Apple...  1680x1050         NaN   \n",
      "\n",
      "                              device_id  api_version  store_id  \\\n",
      "0  beb2cacb-20af-4f05-9c03-c98e54a1b71a          1.0        12   \n",
      "1  b2d1024d-a62e-480d-ade8-20cf7f618270          1.0        29   \n",
      "2  b2cf91cd-456b-4bca-a1a7-a73fac8f4038          1.0         8   \n",
      "3  6071b84f-dba6-429e-8b6c-11baa0126090          1.0        29   \n",
      "4  8224d228-4d84-46aa-b6c7-888df1f35af3          1.0        66   \n",
      "\n",
      "            local_time  ... cart_products[28].option cart_products[29].option  \\\n",
      "0  2020-06-04 12:21:27  ...                      NaN                      NaN   \n",
      "1   2020-06-04 8:21:27  ...                      NaN                      NaN   \n",
      "2  2020-06-04 12:21:25  ...                      NaN                      NaN   \n",
      "3    2020-06-04 8:20:4  ...                      NaN                      NaN   \n",
      "4   2020-06-04 1:21:27  ...                      NaN                      NaN   \n",
      "\n",
      "  option.stone option.pearlcolor option.finish option.price  \\\n",
      "0          NaN               NaN           NaN          NaN   \n",
      "1          NaN               NaN           NaN          NaN   \n",
      "2          NaN               NaN           NaN          NaN   \n",
      "3          NaN               NaN           NaN          NaN   \n",
      "4          NaN               NaN           NaN          NaN   \n",
      "\n",
      "  option.category id option.Kollektion  option.kollektion_id  \\\n",
      "0                NaN               NaN                   NaN   \n",
      "1                NaN               NaN                   NaN   \n",
      "2                NaN               NaN                   NaN   \n",
      "3                NaN               NaN                   NaN   \n",
      "4                NaN               NaN                   NaN   \n",
      "\n",
      "  recommendation_product_position  \n",
      "0                             NaN  \n",
      "1                             NaN  \n",
      "2                             NaN  \n",
      "3                             NaN  \n",
      "4                             NaN  \n",
      "\n",
      "[5 rows x 414 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
